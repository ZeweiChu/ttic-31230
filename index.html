<title>TTIC 31230: Fundamentals of Deep Learning</title>

<header>TTIC 31230: Fundamentals of Deep Learning</header>

<p> David McAllester</p>

<p> Winter 2019</p>

<p><b>Warning:</b> This year the course is going to be more theoretical than in previous years.  There will be problem sets but the grade will be based entirely on exams including a final. There will be no programming project. There will be extensive use of information theory and tensor calculus.  I will generally give permission to take the class but will give an exam after two lectures (worth 10% of total grade) to help people determine if they have an adequate background (no one will be ejected from the class).</p>

<p>This course covers the topics listed below.  Most topics are relevant to most applications --- applications to natural language processing, computer vision, speech recognition, computational biology, and computational chemistry will be integrated into the presentations of the general methods. Course material will be maintained on an external web site (Links to an external site.)Links to an external site.</p>

<ol>
<li>Information theory: entropy, cross-entropy, KL-divergence, mutual information.</li>
<liDeep learning frameworks: computation graphs, back-propagation, minibatching.</li>
<li>Basic Architectures and Einstein Notation: multi-layer perceptrons, Convolutional Neural Networks (Alexnet).  Einstein notation as a framework-independent representation.</li>
<li>Stochastic gradient descent (SGD): standard variations (Vanilla, Adam, RMSProp), minibatch scaling laws, second order methods, Hessian-vector products, SGD-friendly initialization.</li>
<li>More advanced architectures: gated RNNs (LSTMs), resnet, attention.</li>
<li>Generalization and Regularization:  PAC-Bayesian generalization bounds, L2 regularization (shrinkage), dropout.</li>
<li>Autoencoders: rate-distortion autoencoding, variational autoencoding (VAEs) and the evidence lower bound (the ELBO), vector quantized VAEs (VQ-VAE).</li>
<li>Deep graphical models: expectation maximization (EM), expectation gradient (EG), connectionsist temporal classification (CTC), various EG approximations.</li>
<li>Generative Adversarial Networks (GANs): Adversarial optimization, Jensen-Shannon divergence, mode collapse, Wasserstein GANs, progressive GANs.</li>
<li>Deep Reinforcement Learning: The REINFORCE algorithm, policy-gradient theorems, DQN, A3C, AlphaZero.</li>

</ol>



<p>Lectures:</p>

<ol>

  <li><a href = 01intro/intro.html> The Fundamental Equations of Deep Learning</a></li>

  <li><a href = 02MLP/Backprop.html> Back-Propagation and Frameworks</li>  

  <!-- <li><a href = 08InfoTheory/information.html> Information Theory</li>

  <li><a href = 03CNNs/CNNs.html> Convolutional Neural Networks (CNNs) </li>

  <li><a href = 03CNNs/CNNb.html> Invariant Theory </li>

  <li><a href = 04Highway/highway.html> Controling Gradients: Initialization, Batch Normalization, Resnets and Gated RNNs </li>

  <li><a href = 05RNNs/LangModel.html> Language Modeling and Machine Translation</li>

  <li><a href = 06SGD/SGD.html> First Order Stochastic Gradient Descent (SGD)</li>

  <li><a href = 13SGD2/SGD2.html> Gradients as Dual Vectors, Hessian-Vector Products, and Information Geometry </li>

  <li><a href = 07regularization/regularization.html> Regularization</li>

  <li><a href = 17Interpretation/interp.html> Interpretation</li>

  <li><a href = 09GraphicalModels/DGMs.html> Fully Observed Graphical Models I: Exponential Softmax, Sufficient Statistics, and Belief Propagation </li>

  <li><a href = 09GraphicalModels/DGMs2.html> Fully Observed Graphical Models II: Approximate SGD Algorithms</li>

  <li><a href = 09GraphicalModels/DGMs3.html> Partially Observed Graphical Models: Expectation Maximization (EM), Expected Gradient (EG), and CTC</li>

  <li><a href = 11AutoEncoders/Variational.html> Variational Autoencoders (VAEs)</li>

  <li><a href = 11AutoEncoders/Rate.html> Rate-Distortion Autoencoders</li>

  <li><a href = 14GANs/GANs.html> Generative Adversarial Networks (GANs)</li>

  <li><a href = 15RL/RL.html> Reinforcement Learning (RL)</li>

  <li><a href = 16alpha/alpha.html> AlphaZero</li>

  <li><a href = 18AGI/AGI.html> The Quest for Artificial General Intelligence (AGI)</li>

  -->


  

  

</ol>
								  
