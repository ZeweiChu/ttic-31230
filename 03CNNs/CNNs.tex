\input ../SlidePreamble
\input ../preamble

\begin{document}

{\Huge

  \centerline{\bf TTIC 31230, Fundamentals of Deep Learning}
  \bigskip
  \centerline{David McAllester, Winter 2019}

    \vfill
  \centerline{\bf Convolutional Neural Networks (CNNs)}
  \vfill
  \vfill


\slidetwo{What is a CNN?}
{VGG, Zisserman, 2014}

\centerline{\includegraphics[width = 8.0in]{../images/VGG}}
\centerline{\large Davi Frossard}

\slideplain{A Convolution Layer}

\centerline{\includegraphics[width = 2.5in]{../images/Convolution}}
\centerline{$W[\Delta x,\Delta y,i,j]$\hspace{6ex}$L_{\mathrm{IN}}[b,x,y,i]$\hspace{6ex}$L_{\mathrm{out}}[b,x,y,j]$}
\centerline{\large River Trail Documentation}

\vfill
{\tt Procedure CONV}$(W[\Delta x, \Delta y, i, y,], B[j], L_{\mathrm{in}}[b,x,,y,i])$
\begin{eqnarray*}
 & &  \mbox{Return}\;\;L_{\mathrm{out}}[b,x,y,j] \\
 & = &   \left(\sum_{\Delta x, \Delta y, i}\;W[\Delta x, \Delta y, i,j]\; L_{\mathrm{in}}[b,x + \Delta x, y + \Delta y, i]\right) + B[j]
\end{eqnarray*}

\slide{Padding}

\centerline{\includegraphics[height = 2.0in]{../images/padding2}}
\centerline{\large Jonathan Hui}

\vfill
If we pad the input with zeros then the input and output can have the same spatial dimensions.

\slide{Zero Padding in NumPy}

In NumPy we can add a zero padding of width p to an image as follows:

\vfill
\begin{verbatim}
padded = np.zeros(W + 2*p,  H + 2*p)

padded[p:W+p, p:H+p] = x
\end{verbatim}

\slide{Padding}

{\tt Procedure CONV}$(\Phi,\; L_{\mathrm{in}}[b,x,,y,i],\;\mathrm{padding}\;p)$
\vfill
\begin{eqnarray*}
 L'_{\mathrm{in}} & = & \mathrm{Padd}(L_{\mathrm{in}},\;p) \\
 \\
L_{\mathrm{out}}[b,x,y,j] & = &   \left(\sum_{\Delta x, \Delta y, i}\;W[\Delta x, \Delta y, i,j]\; L'_{\mathrm{in}}[b,x + \Delta x, y + \Delta y, i]\right) \\
& & + B[j]
\end{eqnarray*}

\vfill
Return $L_{\mathrm{out}}[b,x,y,j]$

\slide{Strides}

We can move the filter by a ``stride'' $s$ for each spatial step.

\vfill
\begin{eqnarray*}
  L_{\mathrm{out}}[b,x,y,j] & = &  W[\Delta x, \Delta y, i, j] L_{\mathrm{in}}[b,s*x + \Delta x, s*y + \Delta y, i] + B[j]
\end{eqnarray*}

\slide{Max Pooling}

$$L_{\mathrm{out}}[b,x,y,c] = \max_{\Delta x, \Delta y}\; L_{\mathrm{in}}[b,s*x + \Delta x,\; s*y + \Delta y,\; c]$$

\vfill
This is typically done with a stride greater than one so that the image dimension is reduced.



\slide{Fully Connected (FC) Layers}

We reshape $L_{\mathrm{in}}[b,x,y,c]$ to $L_{\mathrm{in}}[b,(x,y,c)]$ and then

\vfill
$$L_{\mathrm{out}}[b,j] = \left(\sum_i \;W[i,j]\;L_{\mathrm{in}}[b,i]\right) + B[j]$$
\slide{Basics}

\begin{itemize}
\item Convolution

\vfill
\item Padding

  \vfill
\item Stides

  \vfill
\item Max Pooling

  \vfill
\item Fully Connected Layers
\end{itemize}

\slide{Alexnet}
{\huge
\centerline{Given Input$[227,227,3]$}

\begin{eqnarray*}
L_1[55 \times 55 \times 96] & = & \relu(\conv(\mathrm{Input},\Phi_1,\mathrm{width}\;11,\pad\;0,\stride\;4)) \\
L_2[27 \times 27 \times 96] & = & \mathrm{MaxPool}(L_1,\mathrm{width}\;3,\stride\;2))  \\
L_3[27 \times 27 \times 256] & = & \relu(\conv(L_2,\Phi_3,\mathrm{width}\;5,\pad\;2,\stride\;1))  \\
L_4[13 \times 13 \times 256] & = & \mathrm{MaxPool}(L_3,\mathrm{width}\;3,\stride\;2))  \\
L_5[13 \times 13 \times 384] & = & \relu(\conv(L_4,\Phi_5,\mathrm{width}\;3,\pad\;1,\stride\;1))  \\
L_6[13 \times 13 \times 384] & = & \relu(\conv(L_5,\Phi_6,\mathrm{width}\;3,\pad\;1,\stride\;1))  \\
L_7[13 \times 13 \times 256] & = & \relu(\conv(L_6,\Phi_7,\mathrm{width}\;3,\pad\;1,\stride\;1))  \\
L_8[6 \times 6 \times 256] & = & \mathrm{MaxPool}(L_7,\mathrm{width}\;3,\stride\;2)) \\
L_9[4096] & = & \relu(\mathrm{FC}(L_8,\Phi_9)) \\
L_{10}[4096] & = & \relu(\mathrm{FC}(L_9,\Phi_{10})) \\
s[1000] & = & \relu(\mathrm{FC}(L_{10},\Phi_s)) \;\;\mbox{class scores}
\end{eqnarray*}
}

\slideplain{VGG, Zisserman, 2014}

\centerline{\includegraphics[width = 9.0in]{../images/VGG}}
\centerline{\large Davi Frossard}

\slide{VGG}
\centerline{\includegraphics[height=4.5in]{../images/VGGStack}}
\centerline{\large Stanford CS231}

\slide{Inception, Google, 2014}

\centerline{\includegraphics[width = 9.0in]{../images/inception1}}
\vfill
\centerline{\includegraphics[width = 3.5in]{../images/inception2}}

\slide{Imagenet Classification}

1000 kinds of objects.

\vfill
\centerline{\includegraphics[height=4.5in]{../images/IVLSRC}}
2016 error rate is 3.0\% \hspace{1.0in} 2017 error rate is 2.25\%

\slideplain{Use Swap Rule to get Backward Method}

\begin{eqnarray*}
  L_{\mathrm{out}}[b,x,y,j] & \pluseq &   W[\Delta x, \Delta y, i, j]\;L_{\mathrm{in}}[b,x + \Delta x, y + \Delta y, i] \\
  \\
  W.\mathrm{grad}[\Delta x, \Delta y,i,j] & \pluseq & \frac{1}{B}\; L_{\mathrm{out}}.\grad[b,x,y,j]\;L_{\mathrm{in}}[b,x + \Delta x,y+ \Delta_y,i]
\end{eqnarray*}

$$L_{\mathrm{in}}.\grad[b,x+\Delta x,y+\Delta y,i,j] \;\pluseq \; L_{\mathrm{out}}.\grad[b,x,y,j]\;W[\Delta x, \Delta y, i, j]$$

\slide{Image to Column (Im2C)}

Reduce convolution to matrix multiplication ---  more space but faster.
{\huge
  $$L_{\mathrm{in}}[b,x,y,\Delta x,\Delta y,i] = L_{\mathrm{in}}[b,x+\Delta x,y+\Delta y,i]$$

\begin{eqnarray*}
  & & L_{\mathrm{out}}[b,x,y,j] \\
  \\
  & = & \left(\sum_{\Delta x, \Delta y, i} W[\Delta x, \Delta y, i, j] *L_{\mathrm{in}}[b,x + \Delta x,\; y + \Delta y,\; i]\right) + B[j] \\
  \\
      & = & \left(\sum_{\Delta x, \Delta y, i} \begin{array}{l}
                                              L_{\mathrm{in}}[b,x,y,\Delta x,\Delta y,i]
                                              * W[\Delta x, \Delta y, i, j] \\
  \end{array}\right) + B[j] \\
  \\
    & = & \left(\sum_{(\Delta x, \Delta y, i)} \begin{array}{l}
                                              L_{\mathrm{in}}[(b,x,j),(\Delta x,\Delta y,i)]
                                              * W[(\Delta x, \Delta y, i), j] \\
                                           \end{array}\right) + B[j]
\end{eqnarray*}
}

\slideplain{Fully Convolutional Networks}

\centerline{\includegraphics[height=4.5in]{../images/dilation}}

\slide{Dilation}

We can ``dilate'' the filter by introducing an image step size $d$ for each step in the filter coordinates.

\vfill
\begin{eqnarray*}
L_{\mathrm{out}}[b,x,y,j] & = &  W[\Delta x, \Delta y, i, j] L_{\mathrm{in}}[b,x + d*\Delta x, y + d*\Delta y, i] + B[j]
\end{eqnarray*}

This is used for ``fully convolutional'' CNNs.



\slideplain{END}

}
\end{document}
