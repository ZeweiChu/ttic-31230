<header>TTIC 31230: Fundamentals of Deep Learning</header>

<p> Generalization and Regularization </p>

<p><a href = regularization.pdf> Slides</a></p>

<p><a href = https://openreview.net/pdf?id=Sy8gdB9xx>  Paper on Over-Parameterization </a></p>

<p><a href =  https://arxiv.org/abs/1307.2118>  PAC-Bayes Tutorial </a></p>

<p><a href =  https://arxiv.org/abs/1703.11008>  A Paper on computing PAC-Bayes bounds in practice (2017) </a></p>

<p><a href = http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks> The Alexnet Paper Demonstraing Dropout (2012) </a></p>

<p><a href = http://jmlr.org/papers/v15/srivastava14a.html> The Journal Dropout Reference (2014)  </a></p>

<p><a href = https://arxiv.org/abs/1512.05287>  Effective Dropout for RNNs (2015) </a></p>

<p><a href = https://arxiv.org/abs/1707.05589> A paper describing exhaustive hyper-parameter search </a></p>

<p><a href = http://www.argmin.net/2016/06/20/hypertuning/ >  Blog post arguing for random sampling of hyper-parameters</a></p>

